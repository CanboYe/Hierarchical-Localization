{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoid too much similarity among the images: skip images while copying "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For task ring_front_right copied  157 images\n",
      "For task ring_front_left copied  157 images\n",
      "For task ring_front_center copied  157 images\n",
      "For task ring_rear_right copied  157 images\n",
      "For task ring_rear_left copied  157 images\n",
      "For task ring_side_right copied  235 images\n",
      "For task ring_side_left copied  235 images\n",
      "For task stereo_front_right copied  40 images\n",
      "For task stereo_front_left copied  40 images\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "image_dir = '/home/cloudlet/datasets/argoverse-tracking/sample/c6911883-1843-3727-8eaa-41dc8cda8993/'\n",
    "output_dir_db = '/home/cloudlet/datasets/argoverse-tracking/sample/test_1017_2/db/'\n",
    "if not os.path.exists(output_dir_db):\n",
    "    os.makedirs(output_dir_db)\n",
    "output_dir_query = '/home/cloudlet/datasets/argoverse-tracking/sample/test_1017_2/query/'\n",
    "if not os.path.exists(output_dir_query):\n",
    "    os.makedirs(output_dir_query)\n",
    "    \n",
    "task_list_db = ['ring_front_right', 'ring_front_left', 'ring_front_center', 'ring_rear_right', 'ring_rear_left']\n",
    "skip = 3\n",
    "for task in task_list_db:\n",
    "    counter = 0\n",
    "    for filename in glob.glob(image_dir + task + '/*.jpg'):\n",
    "        if counter % skip == 0:\n",
    "            cmd = 'cp '+ filename + ' ' + output_dir_db\n",
    "            os.system(cmd)\n",
    "        counter += 1\n",
    "    print('For task ' + task + ' copied ',  counter//skip + 1, 'images')\n",
    "\n",
    "task_list_query = ['ring_side_right', 'ring_side_left', 'stereo_front_right', 'stereo_front_left']\n",
    "skip = 2\n",
    "for task in task_list_query:\n",
    "    counter = 0\n",
    "    for filename in glob.glob(image_dir + task + '/*.jpg'):\n",
    "        if counter % skip == 0:\n",
    "            cmd = 'cp '+ filename + ' ' + output_dir_query\n",
    "            os.system(cmd)\n",
    "        counter += 1\n",
    "    print('For task ' + task + ' copied ',  counter//skip + 1, 'images')\n",
    "\n",
    "output_dir_db_query = '/home/cloudlet/datasets/argoverse-tracking/sample/test_1017_2/db_query/'\n",
    "if not os.path.exists(output_dir_db_query):\n",
    "    os.makedirs(output_dir_db_query)\n",
    "cmd = 'cp '+ output_dir_db + '/*.jpg ' + output_dir_db_query\n",
    "os.system(cmd)\n",
    "cmd = 'cp '+ output_dir_query + '/*.jpg ' + output_dir_db_query\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cloudlet/anaconda3/envs/hfnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/cloudlet/anaconda3/envs/hfnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/cloudlet/anaconda3/envs/hfnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/cloudlet/anaconda3/envs/hfnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/cloudlet/anaconda3/envs/hfnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/cloudlet/anaconda3/envs/hfnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cloudlet/work/netvlad_tf_open/python/netvlad_tf/nets.py:71: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "WARNING:tensorflow:From /home/cloudlet/work/netvlad_tf_open/python/netvlad_tf/layers.py:40: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "INFO:tensorflow:Restoring parameters from /home/cloudlet/work/netvlad_tf_open/checkpoints/vd16_pitts30k_conv5_3_vlad_preL2_intra_white\n",
      "(201, 300, 3)\n",
      "(1, 201, 300, 3)\n",
      "(1, 4096)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import netvlad_tf.net_from_mat as nfm\n",
    "import netvlad_tf.nets as nets\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "image_batch = tf.placeholder(\n",
    "        dtype=tf.float32, shape=[None, None, None, 3])\n",
    "\n",
    "net_out = nets.vgg16NetvladPca(image_batch)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.Session()\n",
    "saver.restore(sess, nets.defaultCheckpoint())\n",
    "\n",
    "inim = cv2.imread(nfm.exampleImgPath())\n",
    "inim = cv2.cvtColor(inim, cv2.COLOR_BGR2RGB)\n",
    "print(inim.shape)\n",
    "batch = np.expand_dims(inim, axis=0)\n",
    "print(batch.shape)\n",
    "result = sess.run(net_out, feed_dict={image_batch: batch})\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [01:47<00:00,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ring_rear_right_315978414491055520.jpg\n",
      "785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from tqdm import tqdm\n",
    "result_list = []\n",
    "filename_list = []\n",
    "dataset_path = '/home/cloudlet/datasets/argoverse-tracking/sample/test_1017_2/'\n",
    "for filename in tqdm(glob.glob(dataset_path + 'db/*.jpg')):\n",
    "    filename_list.append(filename.split('/')[-1])\n",
    "    inim = cv2.imread(filename)\n",
    "    inim = cv2.cvtColor(inim, cv2.COLOR_BGR2RGB)\n",
    "#     print(inim.shape)\n",
    "    batch = np.expand_dims(inim, axis=0)\n",
    "#     print(batch.shape)\n",
    "    result = sess.run(net_out, feed_dict={image_batch: batch})\n",
    "    result_list.append(result)\n",
    "print(filename_list[5])\n",
    "print(len(filename_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [01:33<00:00,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stereo_front_left_315978407897654688.jpg\n",
      "548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result_list_query = []\n",
    "filename_list_query = []\n",
    "for filename in tqdm(glob.glob(dataset_path + 'query/*.jpg')):\n",
    "    filename_list_query.append(filename.split('/')[-1])\n",
    "    inim = cv2.imread(filename)\n",
    "    inim = cv2.cvtColor(inim, cv2.COLOR_BGR2RGB)\n",
    "#     print(inim.shape)\n",
    "    batch = np.expand_dims(inim, axis=0)\n",
    "#     print(batch.shape)\n",
    "    result = sess.run(net_out, feed_dict={image_batch: batch})\n",
    "    result_list_query.append(result)\n",
    "print(filename_list_query[5])\n",
    "print(len(filename_list_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['query.jpg']\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# this is for the matching test 10.27\n",
    "# Query image\n",
    "base_dir = '/home/cloudlet/work/Hierarchical-Localization/test_query/'\n",
    "result_list_query = []\n",
    "filename_list_query = []\n",
    "for filename in tqdm(glob.glob(base_dir + 'query_image/*.jpg')):\n",
    "    filename_list_query.append(filename.split('/')[-1])\n",
    "    inim = cv2.imread(filename)\n",
    "    inim = cv2.cvtColor(inim, cv2.COLOR_BGR2RGB)\n",
    "#     print(inim.shape)\n",
    "    batch = np.expand_dims(inim, axis=0)\n",
    "#     print(batch.shape)\n",
    "    result = sess.run(net_out, feed_dict={image_batch: batch})\n",
    "    result_list_query.append(result)\n",
    "print(filename_list_query)\n",
    "print(len(filename_list_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(desc1, desc2):\n",
    "    # For normalized descriptors, computing the distance is a simple matrix multiplication.\n",
    "    return 2 * (1 - desc1 @ desc2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 4096)\n"
     ]
    }
   ],
   "source": [
    "db = np.concatenate(result_list, axis=0)\n",
    "print(db.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate pair files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for the matching test 10.27\n",
    "pair_path = base_dir + 'pairs/'\n",
    "top_k = 20\n",
    "import os\n",
    "if not os.path.exists(pair_path):\n",
    "    os.makedirs(pair_path)\n",
    "with open(pair_path + 'pairs'+str(top_k)+'_argo_query.txt', 'w') as file:\n",
    "    for i1, query in enumerate(result_list_query):\n",
    "        query = query.flatten()\n",
    "        dist = compute_distance(query, db)\n",
    "        index_min_k = np.argsort(dist)[:top_k]\n",
    "\n",
    "        for i2, db_file_index in enumerate(index_min_k):\n",
    "            if i2 == len(index_min_k)-1 and i1 == len(result_list_query)-1:\n",
    "                line = filename_list_query[i1] + ' ' + filename_list[db_file_index]\n",
    "            else:\n",
    "                line = filename_list_query[i1] + ' ' + filename_list[db_file_index] + '\\n'\n",
    "            file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_path = '/home/cloudlet/work/Hierarchical-Localization/pairs/argo_1017_2/'\n",
    "top_k = 60\n",
    "import os\n",
    "if not os.path.exists(pair_path):\n",
    "    os.makedirs(pair_path)\n",
    "with open(pair_path + 'pairs'+str(top_k)+'_argo_query.txt', 'w') as file:\n",
    "    for i1, query in enumerate(result_list_query):\n",
    "        query = query.flatten()\n",
    "        dist = compute_distance(query, db)\n",
    "        index_min_k = np.argsort(dist)[:top_k]\n",
    "\n",
    "        for i2, db_file_index in enumerate(index_min_k):\n",
    "            if i2 == len(index_min_k)-1 and i1 == len(result_list_query)-1:\n",
    "                line = filename_list_query[i1] + ' ' + filename_list[db_file_index]\n",
    "            else:\n",
    "                line = filename_list_query[i1] + ' ' + filename_list[db_file_index] + '\\n'\n",
    "            file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 60\n",
    "with open(pair_path + 'pairs'+str(top_k)+'_argo_db.txt', 'w') as file:\n",
    "    for i1, db_image in enumerate(result_list):\n",
    "        db_image = db_image.flatten()\n",
    "        dist = compute_distance(db_image, db)\n",
    "        index_min_k = np.argsort(dist)[1:top_k+1]\n",
    "\n",
    "        for i2, db_file_index in enumerate(index_min_k):\n",
    "            if i2 == len(index_min_k)-1 and i1 == len(result_list)-1:\n",
    "                line = filename_list[i1] + ' ' + filename_list[db_file_index]\n",
    "            else:\n",
    "                line = filename_list[i1] + ' ' + filename_list[db_file_index] + '\\n'\n",
    "            file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate queries_with_intrinsics.txt for localization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tqdm import tqdm\n",
    "dataset_path = '/home/cloudlet/datasets/argoverse-tracking/sample/test_1017_2/'\n",
    "with open(dataset_path + 'queries_with_intrinsics_1017_2.txt', 'w') as file:\n",
    "    image_glob_list = glob.glob(dataset_path + 'query/*.jpg')\n",
    "    for i, filename in enumerate(image_glob_list):\n",
    "        name = filename.split('/')[-1]\n",
    "        if 'ring_rear' in name:\n",
    "            params = '1398.898 956.8 580.9 -0.1681239'\n",
    "# \"focal_length_x_px_\": 1398.8981635526468, \"focal_length_y_px_\": 1398.8981635526468, \n",
    "# \"focal_center_x_px_\": 956.7924764366256, \"focal_center_y_px_\": 580.9004713513332, \n",
    "# \"skew_\": 0.0, \"distortion_coefficients_\": [-0.16812389660709987, 0.1156063782256891, -0.021955074613449775]\n",
    "        elif 'ring_side' in name:\n",
    "            params = '1406.669 969.1 622.6 -0.1700210'\n",
    "# \"focal_length_x_px_\": 1406.668708764027, \"focal_length_y_px_\": 1406.668708764027, \n",
    "# \"focal_center_x_px_\": 969.1274587919514, \"focal_center_y_px_\": 622.6176623508292, \"skew_\": 0.0, \n",
    "# \"distortion_coefficients_\": [-0.170020986074912, 0.11822570242692526, -0.024028975508574642]\n",
    "        elif 'stereo_front_left' in name:\n",
    "            params = '3666.738 1230.5 1059.5 -0.1073885'\n",
    "# \"focal_length_x_px_\": 3666.737987697073, \"focal_length_y_px_\": 3666.737987697073, \n",
    "# \"focal_center_x_px_\": 1230.5215533709008, \"focal_center_y_px_\": 1059.5814244164, \"skew_\": 0.0, \n",
    "# \"distortion_coefficients_\": [-0.10738858957839269, 0.19257998343246094, -0.004826963862134801]\n",
    "        elif 'stereo_front_right' in name:\n",
    "            params = '3663.383 1245.1 1073.9 -0.1057950'\n",
    "# \"focal_length_x_px_\": 3663.3831779453944, \"focal_length_y_px_\": 3663.3831779453944, \n",
    "# \"focal_center_x_px_\": 1245.152498763069, \"focal_center_y_px_\": 1073.9194352453455, \"skew_\": 0.0, \n",
    "# \"distortion_coefficients_\": [-0.10579500162786715, 0.15297214630504186, 0.1282398068572198]\n",
    "        else:\n",
    "            print('error when reading params')\n",
    "            \n",
    "        end_str = '' if i == len(image_glob_list)-1 else '\\n'       \n",
    "        if 'ring_' in name:\n",
    "            line = name + ' SIMPLE_RADIAL 1920 1200 ' + params + end_str\n",
    "        elif 'stereo_' in name:\n",
    "            line = name + ' SIMPLE_RADIAL 2464 2056 ' + params + end_str\n",
    "        else:\n",
    "            print('error when reading cam type')\n",
    "        file.write(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Ground Truth Camera Position for db image\n",
    "So that we could use COLMAP model_aligner to rescale the 3d model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.transform import Rotation\n",
    "import numpy as np\n",
    "\n",
    "def tf_matrix(qvec, tvec):\n",
    "    # suppose argoverse is [qw,qx,qy,qz], while scipy is [qx,qy,qz,qw]\n",
    "    R = Rotation.from_quat([qvec[1], qvec[2], qvec[3], qvec[0]]).as_matrix()\n",
    "    t = np.array(tvec).reshape(3,1)\n",
    "    T = np.concatenate((R, t), axis=1)\n",
    "    T = np.concatenate((T, np.array([[0,0,0,1]])), axis=0)\n",
    "#     print(T)\n",
    "    return T\n",
    "    \n",
    "# tf_matrix([-0.3662878606998999, 0.006933435549559967, 0.006966299178769239, 0.930449676904196],\\\n",
    "#           [2601.869677585785, 1211.1693848655868, 15.694929787299001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "calib_file_dir = '/home/cloudlet/datasets/argoverse-tracking/sample/c6911883-1843-3727-8eaa-41dc8cda8993/vehicle_calibration_info.json'\n",
    "T_vc_front_left = {}\n",
    "T_vc_front_right = {}\n",
    "T_vc_front_center = {}\n",
    "T_vc_rear_left = {}\n",
    "T_vc_rear_right = {}\n",
    "with open(calib_file_dir) as json_file: \n",
    "    calib = json.load(json_file) \n",
    "#     print(calib['camera_data_'])\n",
    "    for item in calib['camera_data_']:\n",
    "        if 'ring_front_left' in item['key']:\n",
    "            pose =  item['value']['vehicle_SE3_camera_']\n",
    "            T_vc_front_left = {'rotation': pose['rotation']['coefficients'],\\\n",
    "                               'translation': pose['translation']}\n",
    "\n",
    "        if 'ring_front_right' in item['key']:\n",
    "            pose =  item['value']['vehicle_SE3_camera_']\n",
    "            T_vc_front_right = {'rotation': pose['rotation']['coefficients'],\\\n",
    "                               'translation': pose['translation']}\n",
    "        if 'ring_front_center' in item['key']:\n",
    "            pose =  item['value']['vehicle_SE3_camera_']\n",
    "            T_vc_front_center = {'rotation': pose['rotation']['coefficients'],\\\n",
    "                               'translation': pose['translation']}\n",
    "\n",
    "        if 'ring_rear_left' in item['key']:\n",
    "            pose =  item['value']['vehicle_SE3_camera_']\n",
    "            T_vc_rear_left = {'rotation': pose['rotation']['coefficients'],\\\n",
    "                               'translation': pose['translation']}\n",
    "            \n",
    "        if 'ring_rear_right' in item['key']:\n",
    "            pose =  item['value']['vehicle_SE3_camera_']\n",
    "            T_vc_rear_right = {'rotation': pose['rotation']['coefficients'],\\\n",
    "                               'translation': pose['translation']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [00:00<00:00, 2565.23it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_path = '/home/cloudlet/datasets/argoverse-tracking/sample/test_1017_2/'\n",
    "image_dir = dataset_path + 'db/'\n",
    "pose_dir = '/home/cloudlet/datasets/argoverse-tracking/sample/c6911883-1843-3727-8eaa-41dc8cda8993/poses/'\n",
    "count = 0\n",
    "\n",
    "with open(dataset_path + 'db_location_1017_2.txt', 'w') as location_file:\n",
    "    for filename in tqdm(glob.glob(image_dir + '*.jpg')):\n",
    "        img_name = filename.split('/')[-1]\n",
    "        ts = img_name.split('_')[-1]\n",
    "        if ts.endswith('.jpg'):\n",
    "            ts = ts[:-4]\n",
    "        else:\n",
    "            print('wrong image name format')\n",
    "\n",
    "        with open(pose_dir + 'city_SE3_egovehicle_' + ts + '.json') as json_file: \n",
    "            pose_wv = json.load(json_file) # vehicle to world\n",
    "            qvec = pose_wv['rotation']\n",
    "            tvec = pose_wv['translation']\n",
    "            T_wv = tf_matrix(qvec,tvec)\n",
    "            if 'front_left' in img_name:\n",
    "                pose_vc = T_vc_front_left\n",
    "            elif 'front_right' in img_name:\n",
    "                pose_vc = T_vc_front_right\n",
    "            elif 'front_center' in img_name:\n",
    "                pose_vc = T_vc_front_center\n",
    "            elif 'rear_right' in img_name:\n",
    "                pose_vc = T_vc_rear_right\n",
    "            elif 'rear_left' in img_name:\n",
    "                pose_vc = T_vc_rear_left\n",
    "            else:\n",
    "                print('error when reading pose_vc')\n",
    "        T_vc = tf_matrix(pose_vc['rotation'], pose_vc['translation'])\n",
    "\n",
    "        T_wc = T_wv @ T_vc\n",
    "#         print(T_vc)\n",
    "        t = T_wc[:3, 3]\n",
    "#         print(t)\n",
    "        \n",
    "        line = img_name + ' ' + ' '.join([str(val) for val in t]) + '\\n' \n",
    "        location_file.write(line)\n",
    "#         print(line)\n",
    "#         count += 1\n",
    "#         if count == 3:\n",
    "#              break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "colmap model_aligner --input_path ./1/ --output_path ./geo-registered-model/ --ref_images_path ~/work/netvlad_tf_open/python/db_location.txt --robust_alignment_max_error 0.5\n",
    "\n",
    "Aligning reconstruction\n",
    "-----------------------\n",
    " => Using 900 reference images\n",
    " => Alignment succeeded\n",
    " => Alignment error: 0.198891 (mean), 0.198105 (median)\n",
    " \n",
    "Aligning reconstruction (after fix T)\n",
    "-----------------------\n",
    " => Using 900 reference images\n",
    " => Alignment succeeded\n",
    " => Alignment error: 0.082774 (mean), 0.061503 (median)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To look at the timestamps of Argoverse data\n",
    "No continous sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'log_id': '25952736-2595-2595-2595-225953853440', 'first': '315966391619461000', 'last': '315966406525337344'}, {'log_id': '6f153f9c-edc5-389f-ac6f-40705c30d97e', 'first': '315966434014592128', 'last': '315966449965293856'}, {'log_id': 'e17eed4f-3ffd-3532-ab89-41a3f24cf226', 'first': '315966968004148448', 'last': '315966983954851216'}, {'log_id': '043aeba7-14e5-3cde-8a5c-639389b6d3a6', 'first': '315967467001566824', 'last': '315967482952273448'}, {'log_id': '10b3a1d8-e56c-38be-aaf7-ef2f862a5c4e', 'first': '315967631819951000', 'last': '315967661910028992'}, {'log_id': '230970eb-dc2e-3133-b252-ff3c6f5d4284', 'first': '315967914019825000', 'last': '315967929944631856'}, {'log_id': '11953248-1195-1195-1195-511954366464', 'first': '315967953220225000', 'last': '315967983119616144'}, {'log_id': 'b3def699-884b-3c9e-87e1-1ab76c618e0b', 'first': '315967986019452848', 'last': '315968001970157032'}, {'log_id': '10b8dee6-778f-33e4-a946-d842d2d9c3d7', 'first': '315968229010579544', 'last': '315968244961283312'}, {'log_id': '88538208-8853-8853-8853-388539396096', 'first': '315968261620332000', 'last': '315968291462938496'}, {'log_id': '84c35ea7-1a99-3a0c-a3ea-c5915d68acbc', 'first': '315969498091017672', 'last': '315969528027738696'}, {'log_id': '8a15674a-ae5c-38e2-bc4b-f4156d384072', 'first': '315969684019978000', 'last': '315969699946504416'}, {'log_id': '26d141ec-f952-3908-b4cc-ae359377424e', 'first': '315970942019879000', 'last': '315970957941003376'}, {'log_id': 'a073e840-6319-3f0b-843e-f6dccdcc7b77', 'first': '315974272001716752', 'last': '315974301971727176'}, {'log_id': '3d20ae25-5b29-320d-8bae-f03e9dc177b9', 'first': '315975023006263472', 'last': '315975038956970504'}, {'log_id': '64c12551-adb9-36e3-a0c1-e43a0e9f3845', 'first': '315975339004156192', 'last': '315975354954858224'}, {'log_id': '273c1883-673a-36bf-b124-88311b1a80be', 'first': '315975639915723192', 'last': '315975654967338816'}, {'log_id': 'f3fb839e-0aa2-342b-81c3-312b80be44f9', 'first': '315976554086649104', 'last': '315976569970757632'}, {'log_id': 'dcdcd8b3-0ba1-3218-b2ea-7bb965aad3f0', 'first': '315977112013457592', 'last': '315977127964162472'}, {'log_id': 'c6911883-1843-3727-8eaa-41dc8cda8993', 'first': '315978406019574000', 'last': '315978421950274464'}]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from tqdm import tqdm\n",
    "dataset_path = '/home/cloudlet/datasets/argoverse-tracking/train1/'\n",
    "log_glob_list = sorted(glob.glob(dataset_path + '*'))\n",
    "# print(log_glob_list)\n",
    "log_list =[]\n",
    "for log_dir in log_glob_list:\n",
    "    log_id = log_dir.split('/')[-1]\n",
    "    pose_json_dir = log_dir + '/poses/'\n",
    "    pose_json_list = glob.glob(pose_json_dir + '*.json')\n",
    "    pose_json_list = sorted(pose_json_list, key=lambda name: int(name[-23:-5]))\n",
    "#     print(pose_json_list)\n",
    "    first_ts = pose_json_list[0].split('/')[-1].split('_')[-1][:-5]\n",
    "    last_ts = pose_json_list[-1].split('/')[-1].split('_')[-1][:-5]\n",
    "    log = {'log_id': log_id, 'first': first_ts, 'last': last_ts}\n",
    "    log_list.append(log)\n",
    "#     print(log)\n",
    "log_sorted = sorted(log_list, key=lambda x: int(x['first']))\n",
    "print(log_sorted)\n",
    "# with open(dataset_path + 'queries_with_intrinsics_1017_2.txt', 'w') as file:\n",
    "#     image_glob_list = glob.glob(dataset_path + 'query/*.jpg')\n",
    "#     for i, filename in enumerate(image_glob_list):\n",
    "#         name = filename.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hfnet",
   "language": "python",
   "name": "hfnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
